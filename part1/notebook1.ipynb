{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c900be",
   "metadata": {},
   "source": [
    "# FSL Project Part 1\n",
    "Feature Extraction, Density Estimation and Bayesian Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3d87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports '''\n",
    "import scipy.io\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, det\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9be004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedFeatures(data_arr):\n",
    "    ''' Calculate mean and std dev of dataset '''\n",
    "    n_imgs = data_arr.shape[0]\n",
    "    # print(n_imgs)\n",
    "    m_arr = np.zeros(n_imgs)\n",
    "    s_arr = np.zeros(n_imgs)\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "        m_arr[i] = np.mean(data_arr[i])\n",
    "        s_arr[i] = np.std(data_arr[i])\n",
    "        \n",
    "    ''' Calculate mean and std dev of the means and std devs respectively '''\n",
    "    M1 = np.mean(m_arr)\n",
    "    M2 = np.mean(s_arr)\n",
    "    S1 = np.std(m_arr)\n",
    "    S2 = np.std(s_arr)\n",
    "    ''' Create array of normalized vectors '''\n",
    "    y = np.zeros((n_imgs, 2))\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "        y[i] = [(m_arr[i]-M1)/S1, (s_arr[i]-M2)/S2]\n",
    "    \n",
    "    return np.transpose(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806979ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrim(x, mean, cov, prior):\n",
    "    maha = distance.mahalanobis(x, mean, inv(cov))\n",
    "    expFac = math.exp(-0.5 * (maha**2))\n",
    "    const = 2 * math.pi * math.sqrt(det(cov))\n",
    "    like = expFac * prior / const\n",
    "    return like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3667bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import training dataset '''\n",
    "train_data = scipy.io.loadmat('train_data.mat')\n",
    "# print(data)\n",
    "\n",
    "train_data_arr = np.array(train_data['data'])\n",
    "label_arr = np.array(train_data['label'][0])\n",
    "# print(dataset.shape)\n",
    "# print(dataset[0][10])\n",
    "# print(label_arr)\n",
    "\n",
    "n_train = train_data_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cd8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import test dataset '''\n",
    "test_data = scipy.io.loadmat('test_data.mat')\n",
    "# print(test_data)\n",
    "test_data_arr = np.array(test_data['data'])\n",
    "test_label_arr = np.array(test_data['label'])[0]\n",
    "# print(test_data_arr.shape)\n",
    "# print(test_label_arr.shape)\n",
    "\n",
    "n_test = test_data_arr.shape[0]\n",
    "# print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f54f89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_y = getNormalizedFeatures(train_data_arr)\n",
    "# print(train_y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a088ff17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_y = getNormalizedFeatures(test_data_arr)\n",
    "# print(test_y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d068d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split features into 3 and 7 classes '''\n",
    "feature_3 = []\n",
    "feature_7 = []\n",
    "\n",
    "train_y = np.transpose(train_y)\n",
    "test_y = np.transpose(test_y)\n",
    "for i in range(n_train):\n",
    "    if label_arr[i] == 3:\n",
    "        feature_3.append(train_y[i])\n",
    "    else:\n",
    "        feature_7.append(train_y[i])\n",
    "\n",
    "feature_3 = np.array(feature_3)\n",
    "feature_7 = np.array(feature_7)\n",
    "# print(feature_3[0])\n",
    "# print(len(feature_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780103a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_3 = np.mean(feature_3, 0)\n",
    "mu_7 = np.mean(feature_7, 0)\n",
    "# print(mu_3)\n",
    "# print(mu_7)\n",
    "\n",
    "''' Calculate variance '''\n",
    "len_3 = len(feature_3)\n",
    "sum_3 = 0\n",
    "for i in range(len_3):\n",
    "    mat = (feature_3[i] - mu_3).reshape(2,1)\n",
    "    trans = mat.reshape(1,2)\n",
    "    sum_3 += mat @ trans\n",
    "sigma_3 = (1/len_3)*sum_3\n",
    "\n",
    "len_7 = len(feature_7)\n",
    "sum_7 = 0\n",
    "for i in range(len_7):\n",
    "    mat = (feature_7[i] - mu_7).reshape(2,1)\n",
    "    trans = mat.reshape(1,2)\n",
    "    sum_7 += mat @ trans\n",
    "sigma_7 = (1/len_7)*sum_7\n",
    "\n",
    "# print(sigma_3)\n",
    "# print(sigma_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbff1d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Case 1: Error probability is 0.15844983966530024\n",
      "Training Data Case 2: Error probability is 0.10538315677294734\n"
     ]
    }
   ],
   "source": [
    "''' Training Case 1 '''\n",
    "train_case1_output = np.zeros(n_train)\n",
    "train_error_case1 = np.zeros(n_train)\n",
    "for i in range(n_train):\n",
    "    l3 = discrim(train_y[i], mu_3, sigma_3, 0.5)\n",
    "    l7 = discrim(train_y[i], mu_7, sigma_7, 0.5)\n",
    "    if l3 > l7:\n",
    "        train_case1_output[i] = 3\n",
    "        train_error_case1[i] = l7\n",
    "    else:\n",
    "        train_case1_output[i] = 7\n",
    "        train_error_case1[i] = l3\n",
    "\n",
    "print(\"Training Data Case 1: Error probability is {}\".format(np.mean(train_error_case1)))\n",
    "\n",
    "''' Training Case 2 '''\n",
    "train_case2_output = np.zeros(n_train)\n",
    "train_error_case2 = np.zeros(n_train)\n",
    "for i in range(n_train):\n",
    "    l3 = discrim(train_y[i], mu_3, sigma_3, 0.3)\n",
    "    l7 = discrim(train_y[i], mu_7, sigma_7, 0.7)\n",
    "    if l3 > l7:\n",
    "        train_case2_output[i] = 3\n",
    "        train_error_case2[i] = l7\n",
    "    else:\n",
    "        train_case2_output[i] = 7\n",
    "        train_error_case2[i] = l3\n",
    "        \n",
    "print(\"Training Data Case 2: Error probability is {}\".format(np.mean(train_error_case2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7db000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Case 1: Error probability is 0.15900897734657957\n",
      "Test Data Case 2: Error probability is 0.10540420592913254\n"
     ]
    }
   ],
   "source": [
    "''' Test Case 1 '''\n",
    "test_case1_output = np.zeros(n_test)\n",
    "test_error_case1 = np.zeros(n_test)\n",
    "for i in range(n_test):\n",
    "    l3 = discrim(test_y[i], mu_3, sigma_3, 0.5)\n",
    "    l7 = discrim(test_y[i], mu_7, sigma_7, 0.5)\n",
    "    if l3 > l7:\n",
    "        test_case1_output[i] = 3\n",
    "        test_error_case1[i] = l7\n",
    "    else:\n",
    "        test_case1_output[i] = 7\n",
    "        test_error_case1[i] = l3\n",
    "        \n",
    "print(\"Test Data Case 1: Error probability is {}\".format(np.mean(test_error_case1)))\n",
    "\n",
    "''' Test Case 2 '''\n",
    "test_case2_output = np.zeros(n_test)\n",
    "test_error_case2 = np.zeros(n_test)\n",
    "for i in range(n_test):\n",
    "    l3 = discrim(test_y[i], mu_3, sigma_3, 0.3)\n",
    "    l7 = discrim(test_y[i], mu_7, sigma_7, 0.7)\n",
    "    if l3 > l7:\n",
    "        test_case2_output[i] = 3\n",
    "        test_error_case2[i] = l7\n",
    "    else:\n",
    "        test_case2_output[i] = 7\n",
    "        test_error_case2[i] = l3\n",
    "        \n",
    "print(\"Test Data Case 2: Error probability is {}\".format(np.mean(test_error_case2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58964dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
