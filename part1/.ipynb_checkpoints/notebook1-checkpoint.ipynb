{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c900be",
   "metadata": {},
   "source": [
    "# FSL Project Part 1\n",
    "Feature Extraction, Density Estimation and Bayesian Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b3d87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports '''\n",
    "import scipy.io\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, det\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7fbe86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedFeatures(data_arr):\n",
    "    ''' Calculate mean and std dev of dataset '''\n",
    "    n_imgs = data_arr.shape[0]\n",
    "    # print(n_imgs)\n",
    "    m_arr = np.zeros(n_imgs)\n",
    "    s_arr = np.zeros(n_imgs)\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "        m_arr[i] = np.mean(data_arr[i])\n",
    "        s_arr[i] = np.std(data_arr[i])\n",
    "        \n",
    "    ''' Calculate mean and std dev of the means and std devs respectively '''\n",
    "    M1 = np.mean(m_arr)\n",
    "    M2 = np.mean(s_arr)\n",
    "    S1 = np.std(m_arr)\n",
    "    S2 = np.std(s_arr)\n",
    "    ''' Create array of normalized vectors '''\n",
    "    y = np.zeros((n_imgs, 2))\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "        y[i] = [(m_arr[i]-M1)/S1, (s_arr[i]-M2)/S2]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7112a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrim(x, mean, cov, prior):\n",
    "    maha = distance.mahalanobis(x, mean, inv(cov))\n",
    "    dfactor = math.log(det(cov))\n",
    "    return -0.5*(maha**2)-0.5*dfactor+math.log(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3667bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import training dataset '''\n",
    "train_data = scipy.io.loadmat('train_data.mat')\n",
    "# print(data)\n",
    "\n",
    "train_data_arr = np.array(train_data['data'])\n",
    "label_arr = np.array(data['label'][0])\n",
    "# print(dataset.shape)\n",
    "# print(dataset[0][10])\n",
    "# print(label_arr)\n",
    "\n",
    "n_train = dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11697f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2886\n"
     ]
    }
   ],
   "source": [
    "''' Import test dataset '''\n",
    "test_data = scipy.io.loadmat('test_data.mat')\n",
    "# print(test_data)\n",
    "test_data_arr = np.array(test_data['data'])\n",
    "test_label_arr = np.array(test_data['label'])[0]\n",
    "# print(test_data_arr.shape)\n",
    "# print(test_label_arr.shape)\n",
    "\n",
    "n_test = test_data_arr.shape[0]\n",
    "# print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f58cc12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15069489  0.12996069]\n",
      " [-0.97386658 -0.93473171]\n",
      " [-0.60346935 -0.6292426 ]]\n"
     ]
    }
   ],
   "source": [
    "train_y = getNormalizedFeatures(train_data_arr)\n",
    "print(train_y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7d068d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split features into 3 and 7 classes '''\n",
    "feature_3 = []\n",
    "feature_7 = []\n",
    "\n",
    "for i in range(n_train):\n",
    "    if label_arr[i] == 3:\n",
    "        feature_3.append(train_y[i])\n",
    "    else:\n",
    "        feature_7.append(train_y[i])\n",
    "\n",
    "feature_3 = np.array(feature_3)\n",
    "feature_7 = np.array(feature_7)\n",
    "# print(feature_3[0])\n",
    "# print(len(feature_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2758c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37687996 0.31851855]\n",
      "[-0.36900004 -0.31185886]\n",
      "[[1.0491056  0.98717364]\n",
      " [0.98717364 0.96037982]]\n",
      "[[0.67669136 0.74435619]\n",
      " [0.74435619 0.842203  ]]\n"
     ]
    }
   ],
   "source": [
    "mu_3 = np.mean(feature_3, 0)\n",
    "mu_7 = np.mean(feature_7, 0)\n",
    "print(mu_3)\n",
    "print(mu_7)\n",
    "\n",
    "''' Calculate variance '''\n",
    "len_3 = len(feature_3)\n",
    "sum_3 = 0\n",
    "for i in range(len_3):\n",
    "    mat = (feature_3[i] - mu_3).reshape(2,1)\n",
    "    trans = mat.reshape(1,2)\n",
    "    sum_3 += mat @ trans\n",
    "sigma_3 = (1/len_3)*sum_3\n",
    "\n",
    "len_7 = len(feature_7)\n",
    "sum_7 = 0\n",
    "for i in range(len_7):\n",
    "    mat = (feature_7[i] - mu_7).reshape(2,1)\n",
    "    trans = mat.reshape(1,2)\n",
    "    sum_7 += mat @ trans\n",
    "sigma_7 = (1/len_7)*sum_7\n",
    "\n",
    "''' TODO: Task 2 - Confirm value of mean and variance '''\n",
    "print(sigma_3)\n",
    "print(sigma_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f5e9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Using the formula g(x) = ln(likelihood) + ln(prior) '''\n",
    "''' Training Case 1: Classification '''\n",
    "train_case1_output = np.zeros(n_imgs)\n",
    "for i in range(n_imgs):\n",
    "    g3 = discrim(y[i], mu_3, sigma_3, 0.5)\n",
    "    g7 = discrim(y[i], mu_7, sigma_3, 0.5)\n",
    "    if g3 > g7:\n",
    "        train_case1_output[i] = 3\n",
    "    else:\n",
    "        train_case1_output[i] = 7\n",
    "\n",
    "''' Training Case 2: Classification '''\n",
    "train_case2_output = np.zeros(n_imgs)\n",
    "for i in range(10):\n",
    "    g3 = discrim(y[i], mu_3, sigma_3, 0.3)\n",
    "    g7 = discrim(y[i], mu_7, sigma_3, 0.7)\n",
    "    if g3 > g7:\n",
    "        train_case2_output[i] = 3\n",
    "    else:\n",
    "        train_case2_output[i] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e63a0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.27642966  1.17904022]\n",
      " [ 0.32451918  0.49973571]\n",
      " [ 1.26264329  1.10318912]\n",
      " [ 2.60889625  2.12969339]\n",
      " [-0.07164414 -0.10773717]\n",
      " [-1.15218415 -1.31728734]\n",
      " [ 0.89860483  0.87134993]\n",
      " [-0.94968045 -1.07152469]\n",
      " [ 0.01224468  0.14448575]\n",
      " [-0.54896502 -0.5212292 ]]\n"
     ]
    }
   ],
   "source": [
    "test_y = getNormalizedFeatures(test_data_arr)\n",
    "# print(test_y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b9bacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case1_output = np.zeros(n_test)\n",
    "for i in range(n_test):\n",
    "    g3 = discrim(test_y[i], mu_3, sigma_3, 0.5)\n",
    "    g7 = discrim(test_y[i], mu_7, sigma_3, 0.5)\n",
    "    if g3 > g7:\n",
    "        test_case1_output[i] = 3\n",
    "    else:\n",
    "        test_case1_output[i] = 7\n",
    "\n",
    "''' Training Case 2: Classification '''\n",
    "test_case2_output = np.zeros(n_test)\n",
    "for i in range(n_test):\n",
    "    g3 = discrim(test_y[i], mu_3, sigma_3, 0.3)\n",
    "    g7 = discrim(test_y[i], mu_7, sigma_3, 0.7)\n",
    "    if g3 > g7:\n",
    "        test_case2_output[i] = 3\n",
    "    else:\n",
    "        test_case2_output[i] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cad9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
